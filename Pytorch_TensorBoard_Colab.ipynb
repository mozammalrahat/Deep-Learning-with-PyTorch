{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n"
      ],
      "metadata": {
        "id": "C9LIrLLeA64f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn  \n",
        "import torch.optim as optim  \n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets \n",
        "import torchvision.transforms as transforms \n",
        "from torch.utils.data import (\n",
        "    DataLoader,\n",
        ")  \n",
        "from torch.utils.tensorboard import SummaryWriter "
      ],
      "metadata": {
        "id": "Qu8n8NlmZxuA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple CNN Architecture"
      ],
      "metadata": {
        "id": "e5_AfVOiBOSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels, out_channels=8, kernel_size=3, stride=1, padding=1\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1\n",
        "        )\n",
        "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "JPT_kAmMAda9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set device "
      ],
      "metadata": {
        "id": "ILGVIljKBUed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "k463d5XiAhSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Declaring Hyperparameters"
      ],
      "metadata": {
        "id": "UEk86ywPBYAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels = 1\n",
        "num_classes = 10\n",
        "num_epochs = 3"
      ],
      "metadata": {
        "id": "MQF84ewZAh8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Dataset"
      ],
      "metadata": {
        "id": "ktPmBJm3BcFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(\n",
        "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "gbaGlkrcAngx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To do Hyperparameter Search"
      ],
      "metadata": {
        "id": "nRnVl13dBk7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sizes = [32, 256]\n",
        "learning_rates = [1e-2, 1e-3, 1e-4, 1e-5]\n",
        "classes = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]"
      ],
      "metadata": {
        "id": "odjN_hcCArOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training The Model"
      ],
      "metadata": {
        "id": "dp3kdhxtBuAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_size in batch_sizes:\n",
        "    for learning_rate in learning_rates:\n",
        "        \n",
        "        step = 0\n",
        "        model = CNN(in_channels=in_channels, num_classes=num_classes)\n",
        "        model.to(device)\n",
        "        model.train()\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        train_loader = DataLoader(\n",
        "            dataset=train_dataset, batch_size=batch_size, shuffle=True\n",
        "        )\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0)\n",
        "        writer = SummaryWriter(\n",
        "            f\"runs/MNIST/MiniBatchSize {batch_size} LR {learning_rate}\"\n",
        "        )\n",
        "\n",
        "        images, _ = next(iter(train_loader))\n",
        "        writer.add_graph(model, images.to(device))\n",
        "        writer.close()\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            losses = []\n",
        "            accuracies = []\n",
        "\n",
        "            for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "                \n",
        "                data = data.to(device=device)\n",
        "                targets = targets.to(device=device)\n",
        "\n",
        "                # forward\n",
        "                scores = model(data)\n",
        "                loss = criterion(scores, targets)\n",
        "                losses.append(loss.item())\n",
        "\n",
        "                # backward\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Calculate 'running' training accuracy\n",
        "                features = data.reshape(data.shape[0], -1)\n",
        "                img_grid = torchvision.utils.make_grid(data)\n",
        "                _, predictions = scores.max(1)\n",
        "                num_correct = (predictions == targets).sum()\n",
        "                running_train_acc = float(num_correct) / float(data.shape[0])\n",
        "                accuracies.append(running_train_acc)\n",
        "\n",
        "                # For plotting things in tensorboard\n",
        "                class_labels = [classes[label] for label in predictions]\n",
        "                writer.add_image(\"mnist_images\", img_grid)\n",
        "                writer.add_histogram(\"fc1\", model.fc1.weight)\n",
        "                writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "                writer.add_scalar(\n",
        "                    \"Training Accuracy\", running_train_acc, global_step=step\n",
        "                )\n",
        "\n",
        "                if batch_idx == 230:\n",
        "                    writer.add_embedding(\n",
        "                        features,\n",
        "                        metadata=class_labels,\n",
        "                        label_img=data,\n",
        "                        global_step=batch_idx,\n",
        "                    )\n",
        "                step += 1\n",
        "\n",
        "            writer.add_hparams(\n",
        "                {\"lr\": learning_rate, \"bsize\": batch_size},\n",
        "                {\n",
        "                    \"accuracy\": sum(accuracies) / len(accuracies),\n",
        "                    \"loss\": sum(losses) / len(losses),\n",
        "                },\n",
        "            )"
      ],
      "metadata": {
        "id": "GmtVlX57A06T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installing The Tensorboard if not Available"
      ],
      "metadata": {
        "id": "obJufKfWCJgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8AY5jSAadIi",
        "outputId": "31d9c45f-5679-48e4-e60c-7ad05ca2a4d8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.9/dist-packages (2.12.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (2.2.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (1.22.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (0.7.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (67.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (0.40.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (1.53.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (2.17.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (2.27.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (3.4.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard) (6.3.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Closing the SummaryWriter instance"
      ],
      "metadata": {
        "id": "Ukd14zt_CRly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writer.close()"
      ],
      "metadata": {
        "id": "bOxBeiRgcnTl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load TensorBoard"
      ],
      "metadata": {
        "id": "crDtvzi6Cipz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3Md_UtTeVLy",
        "outputId": "0a5e3fbc-ae76-4484-d031-26878cfa3629"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start TensorBoard"
      ],
      "metadata": {
        "id": "6HHjchgICoxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir runs/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CN9F-R-aeZG",
        "outputId": "82f16146-4f2f-47f8-c883-ea331d3b0012"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-16 17:13:59.049457: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server)\n",
            "/usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server)\n",
            "/usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server)\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.12.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "W0416 17:14:32.625130 140663810127616 plugin_event_accumulator.py:369] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
            "W0416 17:14:33.296636 140663810127616 plugin_event_accumulator.py:369] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/werkzeug/serving.py\", line 766, in serve_forever\n",
            "    super().serve_forever(poll_interval=poll_interval)\n",
            "  File \"/usr/lib/python3.9/socketserver.py\", line 232, in serve_forever\n",
            "    ready = selector.select(poll_interval)\n",
            "  File \"/usr/lib/python3.9/selectors.py\", line 416, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
            "    sys.exit(run_main())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tensorboard/main.py\", line 46, in run_main\n",
            "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tensorboard/program.py\", line 276, in main\n",
            "    return runner(self.flags) or 0\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tensorboard/program.py\", line 295, in _run_serve_subcommand\n",
            "    server.serve_forever()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/werkzeug/serving.py\", line 766, in serve_forever\n",
            "    super().serve_forever(poll_interval=poll_interval)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Open TensorBoard Data in TensorBoard.dev"
      ],
      "metadata": {
        "id": "MTUA-ilhCv8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev upload --logdir runs \\\n",
        "--name \"My latest experiment\" \\\n",
        "--description \"Simple comparison of several hyperparameters\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnE1gcQGfZI-",
        "outputId": "3df330ad-c3c6-4136-d9f7-a209224b9d28"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-16 17:20:54.359947: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Upload started and will continue reading any new data as it's added to the logdir.\n",
            "\n",
            "To stop uploading, press Ctrl-C.\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/bdtro500SxS93NiAAH4Pmg/\n",
            "\n",
            "\u001b[1m[2023-04-16T17:20:57]\u001b[0m Started scanning logdir.\n",
            "E0416 17:21:14.795885 140266088019776 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0416 17:21:23.763013 140266088019776 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "\u001b[1m[2023-04-16T17:26:40]\u001b[0m Total uploaded: 53520 scalars, 26820 tensors (171.4 MB), 8 binary objects (45.1 kB)\n",
            "\u001b[90mTotal skipped: 2 binary objects (11.3 kB)\n",
            "\n",
            "\n",
            "Interrupted. View your TensorBoard at https://tensorboard.dev/experiment/bdtro500SxS93NiAAH4Pmg/\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
            "    sys.exit(run_main())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tensorboard/main.py\", line 46, in run_main\n",
            "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tensorboard/program.py\", line 276, in main\n",
            "    return runner(self.flags) or 0\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tensorboard/uploader/uploader_subcommand.py\", line 691, in run\n",
            "    return _run(flags, self._experiment_url_callback)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/tensorboard/uploader/uploader_subcommand.py\", line 124, in _run\n",
            "    intent.execute(server_info, channel)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/grpc/_channel.py\", line 1746, in __exit__\n",
            "    self._close()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/grpc/_channel.py\", line 1732, in _close\n",
            "    self._channel.close(cygrpc.StatusCode.cancelled, 'Channel closed!')\n",
            "  File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 513, in grpc._cython.cygrpc.Channel.close\n",
            "  File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 399, in grpc._cython.cygrpc._close\n",
            "  File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 429, in grpc._cython.cygrpc._close\n",
            "  File \"/usr/lib/python3.9/threading.py\", line 381, in notify_all\n",
            "    def notify_all(self):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/runs.zip /content/runs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xDh38RfH4t9",
        "outputId": "05f4e171-4d68-4ea3-c30d-47acdc37c3b0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/runs/ (stored 0%)\n",
            "  adding: content/runs/MNIST/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/1681665192.1897235/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/1681665192.1897235/events.out.tfevents.1681665192.97c7e8309fb6.230.48 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/events.out.tfevents.1681665113.97c7e8309fb6.230.45 (deflated 81%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/events.out.tfevents.1681665114.97c7e8309fb6.230.46 (deflated 11%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/00230/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/00230/default/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/00230/default/sprite.png (deflated 6%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/00230/default/tensors.tsv (deflated 93%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/00230/default/metadata.tsv (deflated 66%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/projector_config.pbtxt (deflated 82%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/1681665231.5010521/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/1681665231.5010521/events.out.tfevents.1681665231.97c7e8309fb6.230.49 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/1681665153.0403695/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 1e-05/1681665153.0403695/events.out.tfevents.1681665153.97c7e8309fb6.230.47 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/1681664782.1807437/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/1681664782.1807437/events.out.tfevents.1681664782.97c7e8309fb6.230.32 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/1681664826.352638/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/1681664826.352638/events.out.tfevents.1681664826.97c7e8309fb6.230.33 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/1681664866.8899176/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/1681664866.8899176/events.out.tfevents.1681664866.97c7e8309fb6.230.34 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/events.out.tfevents.1681664740.97c7e8309fb6.230.31 (deflated 11%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/events.out.tfevents.1681664739.97c7e8309fb6.230.30 (deflated 81%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/00230/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/00230/default/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/00230/default/sprite.png (deflated 6%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/00230/default/tensors.tsv (deflated 93%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/00230/default/metadata.tsv (deflated 62%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.01/projector_config.pbtxt (deflated 82%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/1681664144.9550543/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/1681664144.9550543/events.out.tfevents.1681664144.97c7e8309fb6.230.12 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/1681664196.5500286/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/1681664196.5500286/events.out.tfevents.1681664196.97c7e8309fb6.230.13 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/1681664247.5738046/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/1681664247.5738046/events.out.tfevents.1681664247.97c7e8309fb6.230.14 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/events.out.tfevents.1681664092.97c7e8309fb6.230.10 (deflated 81%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/00230/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/00230/default/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/00230/default/sprite.png (deflated 4%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/00230/default/tensors.tsv (deflated 92%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/00230/default/metadata.tsv (deflated 31%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/projector_config.pbtxt (deflated 82%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.01/events.out.tfevents.1681664092.97c7e8309fb6.230.11 (deflated 46%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/1681665113.9149442/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/1681665113.9149442/events.out.tfevents.1681665113.97c7e8309fb6.230.44 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/1681665035.3702583/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/1681665035.3702583/events.out.tfevents.1681665035.97c7e8309fb6.230.42 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/events.out.tfevents.1681664994.97c7e8309fb6.230.40 (deflated 81%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/00230/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/00230/default/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/00230/default/sprite.png (deflated 6%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/00230/default/tensors.tsv (deflated 93%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/00230/default/metadata.tsv (deflated 62%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/projector_config.pbtxt (deflated 82%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/1681665074.745607/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/1681665074.745607/events.out.tfevents.1681665074.97c7e8309fb6.230.43 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.0001/events.out.tfevents.1681664995.97c7e8309fb6.230.41 (deflated 11%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/events.out.tfevents.1681664573.97c7e8309fb6.230.26 (deflated 44%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/1681664683.610573/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/1681664683.610573/events.out.tfevents.1681664683.97c7e8309fb6.230.28 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/events.out.tfevents.1681664572.97c7e8309fb6.230.25 (deflated 81%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/1681664739.773175/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/1681664739.773175/events.out.tfevents.1681664739.97c7e8309fb6.230.29 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/1681664629.2591503/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/1681664629.2591503/events.out.tfevents.1681664629.97c7e8309fb6.230.27 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/00230/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/00230/default/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/00230/default/sprite.png (deflated 3%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/00230/default/tensors.tsv (deflated 92%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/00230/default/metadata.tsv (deflated 33%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 1e-05/projector_config.pbtxt (deflated 82%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/1681664572.898385/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/1681664572.898385/events.out.tfevents.1681664572.97c7e8309fb6.230.24 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/events.out.tfevents.1681664408.97c7e8309fb6.230.20 (deflated 81%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/1681664515.692116/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/1681664515.692116/events.out.tfevents.1681664515.97c7e8309fb6.230.23 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/events.out.tfevents.1681664409.97c7e8309fb6.230.21 (deflated 44%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/1681664461.9453633/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/1681664461.9453633/events.out.tfevents.1681664461.97c7e8309fb6.230.22 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/00230/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/00230/default/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/00230/default/sprite.png (deflated 4%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/00230/default/tensors.tsv (deflated 92%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/00230/default/metadata.tsv (deflated 31%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.0001/projector_config.pbtxt (deflated 82%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/1681664408.9384968/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/1681664408.9384968/events.out.tfevents.1681664408.97c7e8309fb6.230.19 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/events.out.tfevents.1681664247.97c7e8309fb6.230.16 (deflated 45%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/1681664353.5705214/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/1681664353.5705214/events.out.tfevents.1681664353.97c7e8309fb6.230.18 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/events.out.tfevents.1681664247.97c7e8309fb6.230.15 (deflated 81%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/00230/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/00230/default/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/00230/default/sprite.png (deflated 4%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/00230/default/tensors.tsv (deflated 92%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/00230/default/metadata.tsv (deflated 34%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/projector_config.pbtxt (deflated 82%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/1681664299.8446949/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 32 LR 0.001/1681664299.8446949/events.out.tfevents.1681664299.97c7e8309fb6.230.17 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681654532.363755/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681654532.363755/events.out.tfevents.1681654532.97c7e8309fb6.230.2 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681663228.718989/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681663228.718989/events.out.tfevents.1681663228.97c7e8309fb6.230.8 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681664907.7445486/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681664907.7445486/events.out.tfevents.1681664907.97c7e8309fb6.230.37 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681663268.2058642/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681663268.2058642/events.out.tfevents.1681663268.97c7e8309fb6.230.9 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681664952.5405514/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681664952.5405514/events.out.tfevents.1681664952.97c7e8309fb6.230.38 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/events.out.tfevents.1681664867.97c7e8309fb6.230.36 (deflated 11%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681663189.290056/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681663189.290056/events.out.tfevents.1681663189.97c7e8309fb6.230.7 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/events.out.tfevents.1681654493.97c7e8309fb6.230.0 (deflated 81%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681664994.864828/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681664994.864828/events.out.tfevents.1681664994.97c7e8309fb6.230.39 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/events.out.tfevents.1681654494.97c7e8309fb6.230.1 (deflated 11%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681654610.4708052/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681654610.4708052/events.out.tfevents.1681654610.97c7e8309fb6.230.4 (deflated 26%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/events.out.tfevents.1681664866.97c7e8309fb6.230.35 (deflated 81%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/events.out.tfevents.1681663149.97c7e8309fb6.230.5 (deflated 81%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/00230/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/00230/default/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/00230/default/sprite.png (deflated 6%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/00230/default/tensors.tsv (deflated 93%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/00230/default/metadata.tsv (deflated 61%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/projector_config.pbtxt (deflated 82%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681654571.592831/ (stored 0%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/1681654571.592831/events.out.tfevents.1681654571.97c7e8309fb6.230.3 (deflated 27%)\n",
            "  adding: content/runs/MNIST/MiniBatchSize 256 LR 0.001/events.out.tfevents.1681663150.97c7e8309fb6.230.6 (deflated 11%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This is for Running the TensorBoard Files in Local Machine"
      ],
      "metadata": {
        "id": "ktawbb-XIhjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "jORGsyDFH5k2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('/content/runs.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "6iRYJVlvIC48",
        "outputId": "625e5dc8-6725-4037-8228-46ce12a0485f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_17a87170-4306-44c4-9155-419bea318c5f\", \"runs.zip\", 615959988)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}