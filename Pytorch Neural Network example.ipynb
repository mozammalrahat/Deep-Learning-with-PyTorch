{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMENtQr+WCziyKhAKoh9oaR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Imports"],"metadata":{"id":"nYCniL1j7LDF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NvQWUmOI5hXu"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","source":["# Create Fully connected Network"],"metadata":{"id":"ervOOJ3e9TAB"}},{"cell_type":"code","source":["class NN(nn.Module):\n","  def __init__(self, input_size, num_classes):\n","    super(NN, self).__init__()\n","    self.fc1 = nn.Linear(input_size, 50)\n","    self.fc2 = nn.Linear(50,num_classes)\n","\n","  def forward(self, x):\n","    x = F.relu(self.fc1(x))\n","    x = self.fc2(x)\n","    return x"],"metadata":{"id":"Abc_hIOl9X9j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model = NN(784,10)\n","# x = torch.randn(64,784)\n","# print(model(x).shape)"],"metadata":{"id":"ZHBwmpuY_XEz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set Device"],"metadata":{"id":"iL0fBwEK_16T"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"k0MCq5ck_4Bx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hyperparameters"],"metadata":{"id":"KGuggL72LJxj"}},{"cell_type":"code","source":["input_size = 784\n","num_classes = 10\n","learning_rate = 0.001\n","batch_size = 64\n","num_epochs = 20"],"metadata":{"id":"abHSoGbuAONC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Data"],"metadata":{"id":"CHio82wVLQQz"}},{"cell_type":"code","source":["train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)\n","test_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"mJCof2QRA-2L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Initialize network"],"metadata":{"id":"BqUExuVrDzZn"}},{"cell_type":"code","source":["model = NN(input_size=input_size, num_classes=num_classes).to(device)"],"metadata":{"id":"yBkgd3uoCgRG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loss and optimizer"],"metadata":{"id":"BOof4chADwcF"}},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"zH9LkEhnC9iB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train Network"],"metadata":{"id":"zIMDWQCZD-cF"}},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","  for batch_idx, (data, targets) in enumerate(train_loader):\n","    # Get data to cuda if possible\n","    data = data.to(device=device)\n","    targets = targets.to(device=device)\n","\n","    # Get to correct shape\n","    data = data.reshape(data.shape[0],-1)\n","\n","    # Forward\n","    scores = model(data)\n","    loss = criterion(scores, targets)\n","\n","    # backward\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    # Gradient descent or adam step\n","    optimizer.step()\n"],"metadata":{"id":"YJE32OKcD89T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Check accuracy on training and test to see how good our model"],"metadata":{"id":"e7_3anF0Hr3S"}},{"cell_type":"code","source":["def check_accuracy(loader, model):\n","  if loader.dataset.train:\n","    print(\"Checking accuracy on training data\")\n","  else:\n","    print(\"Checking accuracy on test data\")\n","  \n","  num_correct = 0\n","  num_samples = 0\n","  model.eval()\n","\n","  with torch.no_grad():\n","    for x, y in loader:\n","      x = x.to(device=device)\n","      y = y.to(device=device)\n","      x = x.reshape(x.shape[0],-1)\n","\n","      scores = model(x)\n","      _, predictions = scores.max(1)\n","      num_correct+=(predictions==y).sum()\n","      num_samples+=predictions.size(0)\n","\n","    print(f'Got {num_correct/num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n","  # model.train()\n","\n"],"metadata":{"id":"f-q9csl4Hzlj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Check Accuracy"],"metadata":{"id":"qsmFLA0XKrRd"}},{"cell_type":"code","source":["check_accuracy(train_loader, model)\n","check_accuracy(test_loader, model)"],"metadata":{"id":"yvOmLKI1Joho"},"execution_count":null,"outputs":[]}]}