{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "gP1IM5qbcOAh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "72-hu-RZcD6v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG types Configuration"
      ],
      "metadata": {
        "id": "mhC9H9xHcdyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VGG_Types = {\n",
        "    \"VGG11\" : [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG13\" : [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG16\" : [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n",
        "    \"VGG19\" : [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\"],\n",
        "}"
      ],
      "metadata": {
        "id": "hB0nW2RXcWqP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generic VGG Architecture Implementation from Scratch"
      ],
      "metadata": {
        "id": "2fIOzjh9eJRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG_net(nn.Module):\n",
        "  def __init__(self, in_channels = 3, num_classes = 1000, model_type = \"VGG16\"):\n",
        "    super(VGG_net, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.conv_layers = self.create_conv_layers(VGG_Types[model_type])\n",
        "\n",
        "    self.fcs = nn.Sequential(\n",
        "        nn.Linear(512*7*7, 4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(4096,4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(4096,1000)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_layers(x)\n",
        "    x = x.reshape(x.shape[0],-1)\n",
        "    x = self.fcs(x)\n",
        "    return x\n",
        "\n",
        "  def create_conv_layers(self, architecture):\n",
        "    layers = []\n",
        "    in_channels = self.in_channels\n",
        "\n",
        "    for x in architecture:\n",
        "      if type(x) == int:\n",
        "        out_channels = x\n",
        "\n",
        "        layers+=[\n",
        "            nn.Conv2d(\n",
        "                in_channels = in_channels,\n",
        "                out_channels = out_channels,\n",
        "                kernel_size = (3,3),\n",
        "                stride = (1,1),\n",
        "                padding = (1,1),\n",
        "            ),\n",
        "            nn.BatchNorm2d(x),\n",
        "            nn.ReLU(),\n",
        "        ]\n",
        "        in_channels = x\n",
        "      \n",
        "      elif x == \"M\":\n",
        "        layers+=[nn.MaxPool2d(kernel_size = (2,2), stride = (2,2))]\n",
        "    return nn.Sequential(*layers)\n",
        "\n"
      ],
      "metadata": {
        "id": "c-iJseaEe4G9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing The Model Architectures"
      ],
      "metadata": {
        "id": "3VNp0vMBiqRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = VGG_net(in_channels=3, num_classes=1000, model_type=\"VGG16\").to(device)\n",
        "BATCH_SIZE = 16\n",
        "x = torch.randn(16,3,224,224).to(device)\n",
        "print(model(x).shape)\n",
        "assert model(x).shape == torch.Size([BATCH_SIZE, 1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUFWFdapip-o",
        "outputId": "442d695c-0d38-4bcc-be3d-16b2bc579752"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1000])\n"
          ]
        }
      ]
    }
  ]
}